{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1cebaR_J3mVVg0v5rV9W8_mA1IwtQhr-Q","authorship_tag":"ABX9TyNqMTdLthJn4II033NmBlBQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#setup"],"metadata":{"id":"fOQix_kwN_YE"}},{"cell_type":"code","source":["!pip install pyodbc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bQsjLV_98Yv","executionInfo":{"status":"ok","timestamp":1695488151397,"user_tz":180,"elapsed":5987,"user":{"displayName":"Lucas Vital","userId":"02756706924459871945"}},"outputId":"992b643a-f687-46db-c03e-842950e8e554"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyodbc\n","  Downloading pyodbc-4.0.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/343.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/343.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.5/343.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyodbc\n","Successfully installed pyodbc-4.0.39\n"]}]},{"cell_type":"code","source":["#Parameters\n","\n","\n","#configuring odbc\n","import pyodbc\n","\n","server = 'wildfire-data-analytics-server.database.windows.net'\n","database = 'wildfire-data-analytics'\n","username = 'lucasvittal'\n","password = 'Lv300699@$'\n","cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n","cursor = cnxn.cursor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"XJnOo8vhPpuR","executionInfo":{"status":"error","timestamp":1695488156978,"user_tz":180,"elapsed":395,"user":{"displayName":"Lucas Vital","userId":"02756706924459871945"}},"outputId":"699897a5-93bc-4608-e4b3-c63e9a170772"},"execution_count":3,"outputs":[{"output_type":"error","ename":"Error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e7ced9f092a9>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0musername\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lucasvittal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Lv300699@$'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcnxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyodbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DRIVER={SQL Server};SERVER='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m';DATABASE='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m';UID='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m';PWD='\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mError\u001b[0m: ('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'SQL Server' : file not found (0) (SQLDriverConnect)\")"]}]},{"cell_type":"markdown","source":["# Análise das queimadas na última década\n","\n","\n","\n","\n","Na última década o fenômenos de incêndios florestais,mas comumente mencionadas como queimadas aqui no brasil, tem chamado cada vez mais atenção mundialmente. As queimadas estão cada vez mais frequentes e intensas e tem causada devastações e perdas que tem  quebrado recordes sobre tudo nos últimos anos. Tendo em vista as catástrofes ocorridas noa Havaí e  no Canadá esse ano tal fenômeno chamou minha atenção de modo a senti-me engajado em tentar entender por meio dos dados o porque tal fenômeno anda  tão frequente e intenso e as verdadeira magnitudes de seu impacto na vida das pessoas que vivem nas área afetadas. Portanto, a ideia nesse trabalho é obter os dados necessários para responder as seguintes indagações:\n","\n","\n","- Sobre evolução das queimadas na última década:\n","\n","  - Como tem sido a evolução das queimadas nessa última decada ?\n","  - Como tem sido a evolução em intensidade dos incêndia nessa última década?\n","\n","- Análise do perfil das localidades onde as queimadas ocorrem com maior frequência e intensidade:\n","\n","  - Onde tem acontecido os incendios com mais intensidade ?\n","  - Qual a caracterítica desses locais em termos de localização espacial, temperatura, umidade, vegetação?\n","\n","\n","- Sobre Perdas em termos de vegestação e  impactado na vida das pessoas:\n","\n","  -  Perdas médias globais de vegetação\n","  -  Perdas média de vegetação por continente\n","  -  Perda média  de vegetação nos países afetados\n","  - Perdas ecômicas ( média global, continental, e por país) devido as queimadas\n","  - impacto na qualidade do ar\n","\n","-  Sobre a relação entre as mudanças climáticas e o aumento das queimadas:\n","  \n","  - Emissões de carbono\n","  - aumento da temperatura\n","  - Relação entre aumento da temperatura global e local por país\n","  \n","\n","\n","  \n","  Sendo assim o objetivo deste trabalho é responder as pesguntas acima de  modo que o compilado de resposta forme uma resposta consistente sobre a pergunta principal:\n","\n","  ***Porque as queimadas tem aumentado tanto em frequência e intensidade na última década ?***\n","\n","  De modo a compreender todos os fatores a ela elencados. Para se chegar a esse compilado de respostas a ideia é usar os conhecimento  aprendidos essa Sprint realizando a coleta dos dados, a sua modelagem de forma adequada adequada e construção de um catálogo de dados, a carga desses dados numa infraestrutura de nuvem e construção de um pipeline de tratamento,  a análise dos dados para finalmente se obter a resposta e com isso se tirar um conclusão final a cerca da principal resposta buscada.\n","  \n","  \n"],"metadata":{"id":"C7xXAyxaZHXm"}},{"cell_type":"markdown","source":["# Busca e coleta de dados\n","\n","Buscando responde cada uma das perguntas acima, buscou-se dados  referentes a cada um do aspectos em que se entendeu como parte da pergunta principal. Sendo assim dos dados que foram encontrados, os seguintes abaixo foram entendidos como relevates para as respostas buscadas:\n","\n","\n","**evolução das queimadas na última década**  \n","   - [Monthly burned area [ha] by landcover class for years 2002-2019 - EU](https://gwis.jrc.ec.europa.eu/apps/country.profile/downloads)\n","   \n","\n","**Característica de vegetação por localização**\n","  - [LANDCOVER DATASET - OCDE](https://stats.oecd.org/Index.aspx?DataSetCode=LAND_COVER)\n","\n","\n","**Média temperatura por país**\n","  - [Temperatura all Countries](https://www.kaggle.com/datasets/subhamjain/temperature-of-all-countries-19952020/code)\n","  -  [Mean global temperature  - Berkeley University](https://berkeleyearth.org/data/)\n","  - [Mean Temperature Cites on Canada - climate data](https://climatedata.ca/download/#station-download)\n","  - [Average monthly temperature by us state - kaggle](https://www.kaggle.com/datasets/justinrwong/average-monthly-temperature-by-us-state)\n","  - [Hawaii monthly average temperatures kahului - nceii noa](https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/city/time-series/USW00022516)\n","\n","\n","**Média anual de precipitação**\n"," - [precipation per country - World Bank](https://data.worldbank.org/indicator/AG.LND.PRCP.MM?end=2020&start=1961)\n","\n","\n","**Perdas em aspecto econômicos e mortes devido as queimadas**\n","\n","  - [Global economic Losses and deaths due to wildfires -  World Bank](https://data.worldbank.org/indicator/AG.LND.PRCP.MM?end=2020&start=1961)\n","  - [Disaster Database -  EM Data](https://public.emdat.be/data)\n","\n","\n","   **Emissiões Anuais de carbono por país**\n","  -  [ CO2 Emissions - Ourworld Daata](https://ourworldindata.org/co2-dataset-sources)\n","  -  [Greenhouse gas emissions - OCDE](https://stats.oecd.org/Index.aspx?DataSetCode=air_ghg)\n","  -  [ CO2 Emissions - World Bank](https://data.worldbank.org/indicator/EN.ATM.CO2E.PC)"],"metadata":{"id":"hpDsB_rfEp6l"}},{"cell_type":"markdown","source":["Tendo em vista que o que se deseja obter como fonte para camada de visualização é um Datawarehouse, fez-se então uma análise mais aprofundadada dos dados coletados selecionando os dados que de fato eram relevantes para a análise a ser realizada. Muitos dos dados encontrados eram redudantes, porém algumas tabelas apresentavam-se mais completas do que outras e foram justamente essas tabelas as quais foi dada a prioriadade na seleção. Uma vez selecionadas as  tabelas, quebrou-se essas tabelas em uma tabela fato e as tabelas  dimensões correspondentes. Tal divisáo fora feita considerando as principais métricas que deveriam ser obtidas as quais tinham que estar na tabela fato, já as tabelas dimensões foram definidas com campos que definiam algum aspecto de granularidade relativa as métricas principais que deveriam ser obitidas a partir da tabela fato. Muitas tabelas  fatos acabaram por compartilha as mesma dimensões então a mesma pode ser aproveitada para outra análise de métrica ao qul se desejou  realizar. A partir desse processo obteve-se um modelo de DW abaixo, onde ao todo se obteve um total de 6 tabelas fato:\n","\n","\n"],"metadata":{"id":"YACSqgS0KAOk"}},{"cell_type":"markdown","source":["**bold text**# Modelagem Dos Dados\n","\n","Tendo em vista que o que se deseja obter como fonte para camada de visualização é um Datawarehouse, fez-se então uma análise mais aprofundadada dos dados coletados selecionando os dados que de fato eram relevantes para a análise a ser realizada. Muitos dos dados encontrados eram redudantes, porém algumas tabelas apresentavam-se mais completas do que outras e foram justamente essas tabelas as quais foi dada a prioriadade na seleção. Uma vez selecionadas as  tabelas, quebrou-se essas tabelas em uma tabela fato e as tabelas  dimensões correspondentes. Tal divisáo fora feita considerando as principais métricas que deveriam ser obtidas as quais tinham que estar na tabela fato, já as tabelas dimensões foram definidas com campos que definiam algum aspecto de granularidade relativa as métricas principais que deveriam ser obitidas a partir da tabela fato. Muitas tabelas  fatos acabaram por compartilha as mesma dimensões então a mesma pode ser aproveitada para outra análise de métrica ao qul se desejou  realizar. A partir desse processo obteve-se um modelo de DW abaixo, onde ao todo se obteve um total de 6 tabelas fato. O esquema relacional construido a partir desta modelagem pode ser acessado no link abaixo:\n","\n","[WildFire_Analysis_DW_Schema](https://drive.google.com/file/d/1L1eHUI49MDDmFsBoyL3AfaJzykHaSKl0/view?usp=sharing)\n","\n","\n"],"metadata":{"id":"Cr40D_-BJ9Wv"}},{"cell_type":"markdown","source":["## Catálogo de dados"],"metadata":{"id":"6vBIowuKQ8Kq"}},{"cell_type":"code","source":["import os\n","\n"],"metadata":{"id":"ltzjbyziCB8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","def read_json(base_path, filename):\n","  with open(base_path +filename) as q:\n","      json_file =  json.load(q)\n","  return json_file"],"metadata":{"id":"AUMLuslc1Tz-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","#read json and save as excel file\n","\n","folder_content = os.listdir(JSON_CATALOGS_PATH)\n","json_filenames = [json_file for json_file in folder_content if os.path.isfile(os.path.join(JSON_CATALOGS_PATH, json_file))]\n","json_files = [read_json(JSON_CATALOGS_PATH, filename) for filename in json_filenames]\n","for json_file,filename in zip(json_files, json_filenames):\n","  pd.DataFrame(json_file).to_excel(TABLE_CATALOGS_PATH + 'excel/' + filename.replace('.json', '.xlsx'),)\n"],"metadata":{"id":"TI24CBQiE52b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_filenames"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhkTMlmYfEc_","executionInfo":{"status":"ok","timestamp":1694339210242,"user_tz":180,"elapsed":400,"user":{"displayName":"Lucas Vital","userId":"02756706924459871945"}},"outputId":"742eafc8-8b30-404d-8f9b-814e44dc462d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ocde_carbon_emission_per_country_catalog.json',\n"," 'ncei_hawaii_kahului_avg_temperature.json',\n"," 'kaggle_city_temperature_catalog.json',\n"," 'cd_climate_daily_canada_per_state_catalog.json',\n"," 'ocde_land_cover_catalog.json',\n"," 'kaggle_US_average_monthly_temperature_by_state_1950_2022_catalog.json',\n"," 'emdat_disasters_impact_uidds2nac_catalog.json',\n"," 'ncei_mean_global_temperatues_1850_2023_land_sea_catalog.json',\n"," 'gwis_burned_area_full_dataset_2002_2019_catalog.json',\n"," 'mb_avg_preciptation_per_year_catalog.json']"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["#read json and save as csv's files\n","\n","folder_content = os.listdir(JSON_CATALOGS_PATH)\n","json_filenames = [json_file for json_file in folder_content if os.path.isfile(os.path.join(JSON_CATALOGS_PATH, json_file))]\n","json_files = [read_json(JSON_CATALOGS_PATH, filename) for filename in json_filenames]\n","for json_file,filename in zip(json_files, json_filenames):\n","  pd.DataFrame(json_file).to_csv(TABLE_CATALOGS_PATH + 'csv/' + filename.replace('.json', '.csv'), encoding='utf-8')"],"metadata":{"id":"s0JVgu4TJ5EH"},"execution_count":null,"outputs":[]}]}